{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import jieba\n",
    "import time\n",
    "import jieba.analyse\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from collections import Counter\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "import heapq\n",
    "from sklearn.externals import joblib\n",
    "from flask import Flask, jsonify, request\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Get Parameters to DataFrame    \n",
    "    json_ = request.form.to_dict()\n",
    "    # Pridicting\n",
    "    name_test = ['{}'.format(json_)]\n",
    "    name_test = pd.DataFrame(name_test)\n",
    "    name_test = name_test.rename(columns={0: 'name'})\n",
    "    name_test['content_cutted'] = name_test['name'].apply(word_cut)\n",
    "    global code_Tfidf\n",
    "    code_Tfidf = Data_prepara()\n",
    "    content_cutted = pd.Series([dic().doc2bow(x) for x in name_test['content_cutted']])\n",
    "    content_cutted2 = pd.Series(map( lambda x: list(map( lambda y: y[0] ,x)),content_cutted))\n",
    "    testX,clf = model(content_cutted2)\n",
    "    test_pred_label = clf.predict_proba(testX)\n",
    "    max_num_index_list = list(map(test_pred_label[0].tolist().index, heapq.nlargest(5, test_pred_label[0].tolist())))\n",
    "    # msg = ''\n",
    "    d = dict()\n",
    "    for i in range(0,5):\n",
    "        # msg=msg+'標籤:'+clf.classes_[max_num_index_list[i]]+'機率:'+test_pred_label[0][max_num_index_list[i]]+'\\n'\n",
    "        d[i+1] = '標籤{}:'.format(i+1)+str(clf.classes_[max_num_index_list[i]])+',機率:'+str(test_pred_label[0][max_num_index_list[i]])\n",
    "    return jsonify(d)\n",
    "            \n",
    "def word_cut(mytext):\n",
    "    return list(jieba.cut(mytext))\n",
    "def dic():\n",
    "    with open('dictionary.pickle', 'rb') as handle:\n",
    "        dictionary = pickle.load(handle)\n",
    "    return dictionary\n",
    "def Data_prepara():\n",
    "    csv.field_size_limit(int(sys.maxsize/10000000000))\n",
    "    df2=pd.read_csv(r'D:\\Mypython\\專題\\Join-name2.csv', sep=',', engine='python',encoding='utf_8_sig')\n",
    "    df2['content_cutted'] = df2['Join_name'].astype('str').apply(word_cut)\n",
    "    df_Join_name_count = pd.Series([Counter(x) for x in df2['content_cutted']],index=df2['Join_name'].index)\n",
    "    code_tokenGybow = pd.Series([dic().doc2bow(x) for x in df_Join_name_count],index=df2['Join_name'].index)\n",
    "    tfidf = TfidfModel(code_tokenGybow)\n",
    "    code_tokenGyTfidf = pd.Series(tfidf[code_tokenGybow],index=df2['Join_name'].index)\n",
    "    code_tokenGyTfidfSort = pd.Series(map( lambda x: sorted(x,key=lambda w: w[1],reverse=True),code_tokenGyTfidf),\n",
    "                                      index=df2['Join_name'].index)\n",
    "    code_tokenGyTfidfSort2 = pd.Series(map( lambda x: x[:len(x)//2],code_tokenGyTfidfSort),\n",
    "                                       index=df2['Join_name'].index)\n",
    "    code_tokenGyTfidfSort3 = pd.Series(map( lambda x: list(map( lambda y: y[0]  ,x)),\n",
    "                                       code_tokenGyTfidfSort),index=df2['Join_name'].index)\n",
    "    code_tokenGyTfidfSort4 = list(code_tokenGyTfidfSort3)\n",
    "    return code_tokenGyTfidfSort4\n",
    "def word(x):\n",
    "    stroke = []\n",
    "    for i in range(0,len(code_Tfidf)):\n",
    "        c = 0\n",
    "        for j in x:\n",
    "            if j in code_Tfidf[i]: #比對分群關鍵字\n",
    "                c = c + 1\n",
    "        stroke.append(c)\n",
    "    return(stroke)\n",
    "def model(x):\n",
    "    AA = []\n",
    "    AA.append(list(x.apply(word)))\n",
    "    df_AA = pd.DataFrame(AA[0])\n",
    "    clf = joblib.load(\"RandomForest_train_model.pkl\")\n",
    "    return df_AA,clf\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"127.0.0.1\",port=6667)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
